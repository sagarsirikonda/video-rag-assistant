# üé• Video RAG Assistant

An intelligent video assistant that allows you to have a conversation with your video content. This application uses a Retrieval-Augmented Generation (RAG) pipeline to transcribe a video, create a searchable knowledge base, and answer your questions with timestamped references.

## Key Features ‚ú®

* **Video Transcription**: Upload any video file (`.mp4`, `.mov`, `.avi`), and the system automatically generates an accurate transcript using OpenAI's Whisper model.
* **Conversational Q&A**: Ask questions in natural language and receive concise, context-aware answers generated by a Large Language Model (LLM).
* **Timestamped Evidence**: Every answer is supported by clickable timestamps that take you to the exact moment in the video where the information was found.
* **Interactive UI**: A clean and user-friendly web interface built with Streamlit, featuring chat history and dynamic video clip display.
* **Efficient Backend**: Utilizes FAISS for fast, in-memory semantic search and caching for optimal performance.

## Technology Stack üõ†Ô∏è

* **Backend**: Python 3.11
* **UI Framework**: Streamlit
* **LLM Orchestration**: LangChain
* **Transcription**: `openai-whisper`
* **LLM Provider**: Groq (easily swappable with OpenAI, Gemini)
* **Vector Store/Search**: FAISS (Facebook AI Similarity Search)
* **Embeddings**: `sentence-transformers`
* **Video Processing**: FFmpeg

---

## üöÄ Setup and Installation

### Prerequisites

* Python 3.11+
* FFmpeg installed on your system and available in your system's PATH.

### 1. Clone the Repository

```bash
git clone [https://github.com/your-username/video-rag-assistant.git](https://github.com/your-username/video-rag-assistant.git)
cd video-rag-assistant

### 2. Create a Virtual Environment

It's highly recommended to use a virtual environment to manage dependencies.

```bash
# For Windows
python -m venv venv
.\\venv\\Scripts\\activate

# For macOS/Linux
python3 -m venv venv
source venv/bin/activate

### 3. Install Dependencies

Install all the required Python libraries using the `requirements.txt` file.

```bash
pip install -r requirements.txt

### 4. Set Up API Keys

You will need an API key from an LLM provider. This project is configured to use Groq by default.

1.  Create a file named `.env` in the root of the project directory.
2.  Add your API key to the file like this:

    ```env
    GROQ_API_KEY="your-secret-api-key-here"
    ```

## ‚ñ∂Ô∏è How to Run the Application

Once the setup is complete, you can run the Streamlit application with a single command:

```bash
streamlit run app.py

A new tab should open in your web browser at `http://localhost:8501`.

## How to Use the App

1.  **Upload a Video**: Use the file uploader in the sidebar to select a video file.
2.  **Wait for Processing**: The application will transcribe the video, create a vector store, and build the RAG chain. The progress will be displayed in the sidebar.
3.  **Ask a Question**: Once processing is complete, use the chat input at the bottom of the screen to ask a question about the video's content.
4.  **View the Answer**: The AI will provide a textual answer.
5.  **Click Timestamps**: Click on the timestamp buttons below the answer to view the corresponding video clip cued to the correct start time.